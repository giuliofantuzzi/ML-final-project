{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#pip install ntscraper\n",
    "from ntscraper import Nitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|██████████| 30/30 [00:41<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "scraper = Nitter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Get tweets\n",
    "Now we can get the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14-Dec-23 23:01:56 - No instance specified, using random instance https://nitter.tinfoil-hat.net\n",
      "14-Dec-23 23:02:03 - Current stats for food: 15 tweets, 0 threads...\n",
      "14-Dec-23 23:02:07 - Current stats for food: 26 tweets, 0 threads...\n",
      "14-Dec-23 23:02:11 - Current stats for food: 32 tweets, 0 threads...\n",
      "14-Dec-23 23:02:15 - Current stats for food: 39 tweets, 0 threads...\n",
      "14-Dec-23 23:02:20 - Current stats for food: 50 tweets, 0 threads...\n",
      "14-Dec-23 23:02:24 - Current stats for food: 64 tweets, 0 threads...\n",
      "14-Dec-23 23:02:28 - Current stats for food: 71 tweets, 0 threads...\n",
      "14-Dec-23 23:02:33 - Current stats for food: 80 tweets, 0 threads...\n",
      "14-Dec-23 23:02:37 - Current stats for food: 84 tweets, 0 threads...\n",
      "14-Dec-23 23:02:42 - Current stats for food: 92 tweets, 0 threads...\n",
      "14-Dec-23 23:02:46 - Current stats for food: 104 tweets, 0 threads...\n",
      "14-Dec-23 23:02:51 - Current stats for food: 114 tweets, 0 threads...\n",
      "14-Dec-23 23:02:56 - Current stats for food: 120 tweets, 0 threads...\n",
      "14-Dec-23 23:03:00 - Current stats for food: 126 tweets, 0 threads...\n",
      "14-Dec-23 23:03:05 - Current stats for food: 129 tweets, 0 threads...\n",
      "14-Dec-23 23:03:10 - Current stats for food: 136 tweets, 0 threads...\n",
      "14-Dec-23 23:03:14 - Current stats for food: 147 tweets, 0 threads...\n",
      "14-Dec-23 23:03:19 - Current stats for food: 156 tweets, 0 threads...\n",
      "14-Dec-23 23:03:23 - Current stats for food: 162 tweets, 0 threads...\n",
      "14-Dec-23 23:03:27 - Current stats for food: 171 tweets, 0 threads...\n",
      "14-Dec-23 23:03:32 - Current stats for food: 178 tweets, 0 threads...\n",
      "14-Dec-23 23:03:36 - Current stats for food: 179 tweets, 0 threads...\n",
      "14-Dec-23 23:03:40 - Current stats for food: 182 tweets, 0 threads...\n",
      "14-Dec-23 23:03:44 - Current stats for food: 188 tweets, 0 threads...\n",
      "14-Dec-23 23:03:48 - Current stats for food: 193 tweets, 0 threads...\n",
      "14-Dec-23 23:03:53 - Current stats for food: 201 tweets, 0 threads...\n",
      "14-Dec-23 23:03:57 - Current stats for food: 208 tweets, 0 threads...\n",
      "14-Dec-23 23:04:02 - Current stats for food: 217 tweets, 0 threads...\n",
      "14-Dec-23 23:04:06 - Current stats for food: 225 tweets, 0 threads...\n",
      "14-Dec-23 23:04:11 - Current stats for food: 235 tweets, 0 threads...\n",
      "14-Dec-23 23:04:16 - Current stats for food: 240 tweets, 0 threads...\n",
      "14-Dec-23 23:04:20 - Current stats for food: 247 tweets, 0 threads...\n",
      "14-Dec-23 23:04:24 - Current stats for food: 256 tweets, 0 threads...\n"
     ]
    }
   ],
   "source": [
    "tweets_food_hashtag=scraper.get_tweets(\"food\",mode=\"hashtag\",number=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3192"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_food_hashtag) #2400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1a) Small trials to discover tweets structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "tweets\n",
      "threads\n"
     ]
    }
   ],
   "source": [
    "print(type(tweets_food_hashtag))\n",
    "for k in tweets_food_hashtag:\n",
    "    print(k)\n",
    "#type(tweets_food_hashtag[\"tweets\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threads is an empty list, since tweets seems interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweets_food_hashtag[\"tweets\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a list...inspect its elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'link': 'https://twitter.com/RujutaDiwekar/status/1732654796623196385#m',\n",
       " 'text': 'Kaali gajar ki kanji-   Good for the gut, for the brain and for everything you care.  P.S. Video uses beetroot as kali gajar isn’t available everywhere.  #winter #food',\n",
       " 'user': {'name': 'Rujuta Diwekar',\n",
       "  'username': '@RujutaDiwekar',\n",
       "  'profile_id': '670857437134479360',\n",
       "  'avatar': 'https://pbs.twimg.com/profile_images/670857437134479360/QRM3YJd0_bigger.jpg'},\n",
       " 'date': 'Dec 7, 2023 · 6:54 AM UTC',\n",
       " 'is-retweet': True,\n",
       " 'external-link': '',\n",
       " 'quoted-post': {},\n",
       " 'stats': {'comments': 22, 'retweets': 80, 'quotes': 2, 'likes': 531},\n",
       " 'pictures': [],\n",
       " 'videos': ['https://video.twimg.com/ext_tw_video/1732653764891557888/pu/vid/avc1/720x1280/Qzr0NEIpKreKrCBG.mp4?tag=12'],\n",
       " 'gifs': []}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_food_hashtag[\"tweets\"][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1b) Create a dataframe of tweets (and their info) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tweets=[]\n",
    "for tweet in tweets_food:\n",
    "    useful_data=[ #tweet text and username\n",
    "                  tweet['text'],\n",
    "                  tweet['user']['username'],\n",
    "                  #stats of the tweet\n",
    "                  tweet['stats']['likes'],\n",
    "                  tweet['stats']['comments'],\n",
    "                  tweet['stats']['retweets'],\n",
    "                  tweet['stats']['quotes'],\n",
    "                  tweet['is-retweet'],\n",
    "                  tweet['external-link'], #useful: an external link might have a bad influence on eng rate!\n",
    "                  #maybe these vars will be encoded in a has/has not binary label\n",
    "                  tweet['pictures'], \n",
    "                  tweet['videos'],\n",
    "                  tweet['gifs']                 \n",
    "                ]       \n",
    "    final_tweets.append(useful_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df dims:  (3192, 11)\n"
     ]
    }
   ],
   "source": [
    "tweets_df= pd.DataFrame(final_tweets,columns= ['text','username','likes','comments','retweets','quotes','is-retweet','external-link','pictures','videos','gifs'])\n",
    "print(\"Df dims: \",tweets_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "NB: a differenza del progetto di indagine stat, qui non credo sia possibile ottenere verificato e \n",
    "lingua del tweet (anche se in realta su get_tweets posso filtrare per lingua....APPROFONDIRE!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export dataset to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "unique_tweets=tweets_df.drop_duplicates(subset=['text','username','likes','comments','retweets','quotes','is-retweet','external-link'],\n",
    "                                        keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df dims:  (1501, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Df dims: \",unique_tweets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB: vedrete che dopo aver aggiunto le informazioni degli users (nell'altro file), il numero di righe del dataset è sceso a 1995 (alcuni utenti in questi giorni hanno messo il profilo privato/ hanno cancellato il profilo)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tweets.to_csv('../../datasets/tweets-data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
